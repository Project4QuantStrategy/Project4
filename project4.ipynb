{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import ensemble\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "future2stock = {'JBF': 3443}\n",
    "future_path = r'processedData_2023\\futures'\n",
    "stock_path = r'processedData_2023\\stocks'\n",
    "\n",
    "future_files = os.listdir(future_path)\n",
    "stock_files = os.listdir(stock_path)\n",
    "\n",
    "# Get all the future tickers\n",
    "future_data = {}\n",
    "stock_data = {}\n",
    "for future_ticker, stock_ticker in future2stock.items():\n",
    "    future_data[future_ticker] = pd.DataFrame()\n",
    "    stock_data[stock_ticker] = pd.DataFrame()\n",
    "    for file in future_files:\n",
    "        if file.startswith(future_ticker):\n",
    "            tmp = pd.read_csv(os.path.join(future_path, file), compression='gzip')    \n",
    "            tmp = tmp[tmp['askPrice1'] > 0]\n",
    "            tmp = tmp[tmp['bidPrice1'] > 0]\n",
    "            tmp = tmp[tmp['askPrice1'] > tmp['bidPrice1']]\n",
    "            future_data[future_ticker] = pd.concat([future_data[future_ticker], tmp])\n",
    "            \n",
    "    for file in stock_files:\n",
    "        if file.startswith(str(stock_ticker)):\n",
    "            tmp = pd.read_csv(os.path.join(stock_path, file), compression='gzip')\n",
    "            tmp = tmp[tmp['SP1'] > 0]\n",
    "            tmp = tmp[tmp['BP1'] > 0]\n",
    "            tmp = tmp[tmp['SP1'] > tmp['BP1']]\n",
    "            stock_data[stock_ticker] = pd.concat([stock_data[stock_ticker], tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select common dates and indexing\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    stockData_dates = np.unique(stockData.date)\n",
    "    stoD=pd.to_datetime(stockData_dates, format=\"%Y-%m-%d\")\n",
    "    qqqq=stoD.year*10000+stoD.month*100+stoD.day\n",
    "    \n",
    "    indexData_dates = np.unique(futureData.date)\n",
    "    indD=pd.to_datetime(indexData_dates, format=\"%Y-%m-%d\")\n",
    "    pppp=indD.year*10000+indD.month*100+indD.day\n",
    "    \n",
    "    commonDays=pd.to_datetime(pppp.intersection(qqqq),format=\"%Y%m%d\")\n",
    "    \n",
    "    d_futures=pd.to_datetime(futureData.date,format=\"%Y-%m-%d\")\n",
    "    futureData.date=d_futures\n",
    "    futureData=futureData[futureData.date.isin(commonDays)]\n",
    "\n",
    "    d_stock=pd.to_datetime(stockData.date,format=\"%Y-%m-%d\")\n",
    "    stockData.date=d_stock\n",
    "    stockData=stockData[stockData.date.isin(commonDays)]\n",
    "\n",
    "    stockData_DateTime = pd.to_datetime(stockData.date.astype(str) + ' ' + stockData.time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
    "    futuresData_DateTime = pd.to_datetime(futureData.date.astype(str) + ' ' + futureData.time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
    "\n",
    "    stockData.index = stockData_DateTime\n",
    "    stockData = stockData[~stockData.index.duplicated(keep='last')]\n",
    "\n",
    "    futureData.index = futuresData_DateTime\n",
    "    futureData = futureData[~futureData.index.duplicated(keep='last')]\n",
    "    \n",
    "    stockData = stockData.sort_index()\n",
    "    futureData = futureData.sort_index()\n",
    "    \n",
    "    stock_data[future2stock[future_ticker]] = stockData\n",
    "    future_data[future_ticker] = futureData\n",
    "    \n",
    "# Downsampling\n",
    "freq = '10s'\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    stockData = stockData.groupby(stockData.index.date).apply(lambda x: x.resample(freq, closed='left', label='right').last()).reset_index(level=0, drop=True)\n",
    "    futureData = futureData.groupby(futureData.index.date).apply(lambda x: x.resample(freq, closed='left', label='right').last()).reset_index(level=0, drop=True)\n",
    "    stockData.fillna(method='ffill', inplace=True)\n",
    "    futureData.fillna(method='ffill', inplace=True)\n",
    "    # get the common index\n",
    "    comon_index = stockData.index.intersection(futureData.index)\n",
    "    stock_data[future2stock[future_ticker]] = stockData.loc[comon_index]\n",
    "    future_data[future_ticker] = futureData.loc[comon_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Slope\n",
    "def cal_slope(df):\n",
    "    # Consider future and stock difference\n",
    "    if 'bidSize1' in df.columns:\n",
    "        bidSizes = [f'bidSize{i}' for i in range(1, 6)]\n",
    "        bidPrices = [f'bidPrice{i}' for i in range(1, 6)]\n",
    "        askSizes = [f'askSize{i}' for i in range(1, 6)]\n",
    "        askPrices = [f'askPrice{i}' for i in range(1, 6)]\n",
    "    else:\n",
    "        bidSizes = [f'BV{i}' for i in range(1, 6)]\n",
    "        bidPrices = [f'BP{i}' for i in range(1, 6)]\n",
    "        askSizes = [f'SV{i}' for i in range(1, 6)]\n",
    "        askPrices = [f'SP{i}' for i in range(1, 6)]\n",
    "\n",
    "    df_bid = df[bidSizes + bidPrices].copy()\n",
    "    df_ask = df[askSizes + askPrices].copy()\n",
    "    df_bid.loc[:, bidPrices] = df_bid[bidPrices] / df[bidPrices[0]].values.reshape(-1, 1)\n",
    "    df_ask.loc[:, askPrices] = df_ask[askPrices] / df[askPrices[0]].values.reshape(-1, 1)\n",
    "    \n",
    "    bid_data = df_bid.values\n",
    "    ask_data = df_ask.values\n",
    "\n",
    "    cum_bid_sizes = np.cumsum(bid_data[:, :5], axis=1) / bid_data[:, :5].sum(axis=1, keepdims=True)\n",
    "    cum_ask_sizes = np.cumsum(ask_data[:, :5], axis=1) / ask_data[:, :5].sum(axis=1, keepdims=True)\n",
    "\n",
    "    bid_price = bid_data[:, 5:]\n",
    "    ask_price = ask_data[:, 5:]\n",
    "\n",
    "    X_bid = cum_bid_sizes - cum_bid_sizes.mean(axis=1, keepdims=True)\n",
    "    Y_bid = bid_price - bid_price.mean(axis=1, keepdims=True)\n",
    "    slope_b = (X_bid * Y_bid).sum(axis=1) / ((X_bid ** 2).sum(axis=1) + 1e-10)\n",
    "\n",
    "    X_ask = cum_ask_sizes - cum_ask_sizes.mean(axis=1, keepdims=True)\n",
    "    Y_ask = ask_price - ask_price.mean(axis=1, keepdims=True)\n",
    "    slope_a = (X_ask * Y_ask).sum(axis=1) / ((X_ask ** 2).sum(axis=1) + 1e-10)\n",
    "\n",
    "    return -slope_b, slope_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features and labels' names to list\n",
    "df_all = {}\n",
    "basicCols = ['date', 'time', 'sAskPrice1','sBidPrice1','sMidQ', 'fAskPrice1','fBidPrice1', 'fMidQ', 'spreadRatio']\n",
    "labelCols = []\n",
    "featureCols = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    labelCols.extend(['Y_M_{}'.format(str(i))])\n",
    "    \n",
    "    featureCols.extend(['fLaggingRtn_{}'.format(str(i))])\n",
    "    featureCols.extend(['spreadRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['volumeImbalanceRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_b_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_a_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_ab_{}'.format(str(i))])\n",
    "    featureCols.extend(['sLaggingRtn_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSpreadRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockVolumeImbalanceRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_b_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_a_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_ab_{}'.format(str(i))])\n",
    "    \n",
    "    for j in range(1, 6):\n",
    "        featureCols.extend(['fAskSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['fBidSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['sAskSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['sBidSize{}_{}'.format(str(j), str(i))])\n",
    "\n",
    "# Generate features and labels\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    unique_dates = np.unique(stockData['date'])\n",
    "    dfs = []\n",
    "    for date in unique_dates:\n",
    "        stockData_date = stockData[stockData['date'] == date]\n",
    "        futureData_date = futureData[futureData['date'] == date]\n",
    "\n",
    "        # Continue to next iteration if stockData_date or futureData_date is empty\n",
    "        if stockData_date.empty or futureData_date.empty:\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(index=stockData_date.index, columns=basicCols+labelCols+featureCols)\n",
    "        df['date'] = stockData_date['date']\n",
    "        df['time'] = stockData_date['time']   \n",
    "             \n",
    "        # Normalize the size\n",
    "        fAskSizeMax = futureData_date[['askSize1', 'askSize2', 'askSize3', 'askSize4', 'askSize5']].max(axis=1)\n",
    "        fBidSizeMax = futureData_date[['bidSize1', 'bidSize2', 'bidSize3', 'bidSize4', 'bidSize5']].max(axis=1)\n",
    "        sAskSizeMax = stockData_date[['SV1', 'SV2', 'SV3', 'SV4', 'SV5']].max(axis=1)\n",
    "        sBidSizeMax = stockData_date[['BV1', 'BV2', 'BV3', 'BV4', 'BV5']].max(axis=1)\n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            df['fAskPrice{}'.format(str(i))] = futureData_date['askPrice{}'.format(str(i))]\n",
    "            df['fBidPrice{}'.format(str(i))] = futureData_date['bidPrice{}'.format(str(i))]\n",
    "            df['fAskSize{}'.format(str(i))] = futureData_date['askSize{}'.format(str(i))] / fAskSizeMax\n",
    "            df['fBidSize{}'.format(str(i))] = futureData_date['bidSize{}'.format(str(i))] / fBidSizeMax\n",
    "            \n",
    "            df['sAskPrice{}'.format(str(i))] = stockData_date['SP{}'.format(str(i))]\n",
    "            df['sBidPrice{}'.format(str(i))] = stockData_date['BP{}'.format(str(i))]\n",
    "            df['sAskSize{}'.format(str(i))] = stockData_date['SV{}'.format(str(i))] / sAskSizeMax\n",
    "            df['sBidSize{}'.format(str(i))] = stockData_date['BV{}'.format(str(i))] / sBidSizeMax\n",
    "        \n",
    "        df['fMidQ'] = (df['fAskPrice1'] + df['fBidPrice1']) / 2\n",
    "        df['slope_b'], df['slope_a'] = cal_slope(futureData_date)\n",
    "        df['slope_ab'] = df['slope_a'] - df['slope_b']\n",
    "        \n",
    "        # Order Imbalance Ratio\n",
    "        ask = np.array([df['fAskPrice{}'.format(str(i))] * df['fAskSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        bid = np.array([df['fBidPrice{}'.format(str(i))] * df['fBidSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        df['spreadRatio'] = (ask - bid) / (ask + bid)\n",
    "\n",
    "        delta_size_bid = np.where(df['fBidPrice1'] < df['fBidPrice1'].shift(1), 0, np.where(df['fBidPrice1'] == df['fBidPrice1'].shift(1), df['fBidSize1'] - df['fBidSize1'].shift(1), df['fBidSize1']))\n",
    "        delta_size_ask = np.where(df['fAskPrice1'].shift(1), 0, np.where(df['fAskPrice1'] == df['fAskPrice1'].shift(1), df['fAskSize1'] - df['fAskSize1'].shift(1), df['fAskSize1']))\n",
    "        df['fOrderImbalance'] = (delta_size_bid - delta_size_ask) / (delta_size_bid + delta_size_ask)\n",
    "\n",
    "        for i in range(1, 11):\n",
    "            df['fLaggingRtn_{}'.format(str(i))] = np.log(df['fMidQ']) - np.log(df['fMidQ'].shift(i))\n",
    "            df['spreadRatio_{}'.format(str(i))] = df['spreadRatio'].shift(i)\n",
    "            df['volumeImbalanceRatio_{}'.format(str(i))] = df['fOrderImbalance'].shift(i)\n",
    "            df['slope_b_{}'.format(str(i))] = df['slope_b'].shift(i)\n",
    "            df['slope_a_{}'.format(str(i))] = df['slope_a'].shift(i)\n",
    "            df['slope_ab_{}'.format(str(i))] = df['slope_ab'].shift(i)\n",
    "            \n",
    "            for j in range(1, 6):\n",
    "                df['fAskSize{}_{}'.format(str(j), str(i))] = df['fAskSize{}'.format(str(j))].shift(i)\n",
    "                df['fBidSize{}_{}'.format(str(j), str(i))] = df['fBidSize{}'.format(str(j))].shift(i)\n",
    "                df['sAskSize{}_{}'.format(str(j), str(i))] = df['sAskSize{}'.format(str(j))].shift(i)\n",
    "                df['sBidSize{}_{}'.format(str(j), str(i))] = df['sBidSize{}'.format(str(j))].shift(i)\n",
    "\n",
    "        # Add stock data\n",
    "        df['sMidQ'] = (stockData_date['SP1'] + stockData_date['BP1'])/2\n",
    "        df['sAskPrice1'] = stockData_date['SP1']\n",
    "        df['sBidPrice1'] = stockData_date['BP1']\n",
    "        df['sMidQ'] = (stockData_date['SP1'] + stockData_date['BP1'])/2\n",
    "        df['stockSlope_b'], df['stockSlope_a'] = cal_slope(stockData_date)\n",
    "        df['stockSlope_ab'] = df['stockSlope_a'] - df['stockSlope_b']\n",
    "        \n",
    "        ask = np.array([df['sAskPrice{}'.format(str(i))] * df['sAskSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        bid = np.array([df['sBidPrice{}'.format(str(i))] * df['sBidSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        df['stockSpreadRatio'] = (ask - bid) / (ask + bid)\n",
    "\n",
    "        delta_size_bid = np.where(df['sBidPrice1'] < df['sBidPrice1'].shift(1), 0, np.where(df['sBidPrice1'] == df['sBidPrice1'].shift(1), df['sBidSize1'] - df['sBidSize1'].shift(1), df['sBidSize1']))\n",
    "        delta_size_ask = np.where(df['sAskPrice1'] > df['sAskPrice1'].shift(1), 0, np.where(df['sAskPrice1'] == df['sAskPrice1'].shift(1), df['sAskSize1'] - df['sAskSize1'].shift(1), df['sAskSize1']))\n",
    "        df['stockOrderImbalance'] = (delta_size_bid - delta_size_ask) / (delta_size_bid + delta_size_ask)\n",
    "\n",
    "        for i in range(1, 11):\n",
    "            df['Y_M_{}'.format(str(i))] = np.log(df['sMidQ'].shift(-i)) - np.log(df['sMidQ'])\n",
    "            \n",
    "            df['sLaggingRtn_{}'.format(str(i))] = np.log(df['sMidQ']) - np.log(df['sMidQ'].shift(i))\n",
    "            df['stockSpreadRatio_{}'.format(str(i))] = df['stockSpreadRatio'].shift(i)\n",
    "            df['stockVolumeImbalanceRatio_{}'.format(str(i))] = df['stockOrderImbalance'].shift(i)\n",
    "            df['stockSlope_b_{}'.format(str(i))] = df['stockSlope_b'].shift(i)\n",
    "            df['stockSlope_a_{}'.format(str(i))] = df['stockSlope_a'].shift(i)\n",
    "            df['stockSlope_ab_{}'.format(str(i))] = df['stockSlope_ab'].shift(i)\n",
    "            \n",
    "            for j in range(1, 6):\n",
    "                df['sAskSize{}_{}'.format(str(j), str(i))] = df['sAskSize{}'.format(str(j))].shift(i)\n",
    "                df['sBidSize{}_{}'.format(str(j), str(i))] = df['sBidSize{}'.format(str(j))].shift(i)\n",
    "        dfs.append(df)\n",
    "    # convert inf to nan to 0\n",
    "    df_all[future_ticker] = pd.concat(dfs, ignore_index=True).replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Done with 8 processes, and time taken is 591.2123265266418\n",
      "Time taken:  593.971914768219 seconds\n"
     ]
    }
   ],
   "source": [
    "# Model Construction and Forecasting\n",
    "def modelConstructionAndForecasting(numOfPastDays:int, numOfForwardDays:int, data:pd.DataFrame, numOfProcesses:int, featureColumns:list, labelColumns:list):\n",
    "    date=data.date\n",
    "    date_index=np.unique(date)\n",
    "    date_num=date_index.size\n",
    "    p=numOfPastDays\n",
    "    \n",
    "    #Output data\n",
    "    columns1 = ['date', 'label', 'isR2', 'oosR2']\n",
    "    outputData = pd.DataFrame(columns=columns1)\n",
    "    \n",
    "    for i in range(date_num-p):\n",
    "        if i >= numOfForwardDays:\n",
    "            break\n",
    "\n",
    "        #Prepare training and testing data for the current testing day\n",
    "        trainingDates=[date_index[i]]\n",
    "        for j in range(i+1,i+p):\n",
    "            trainingDates.append(date_index[j])        \n",
    "\n",
    "        dataPd=data[data.date.isin(trainingDates)]\n",
    "        data1d=data[data.date==date_index[i+p]]\n",
    "\n",
    "        #Building models with gbrt models for each label\n",
    "        gbrtModels = {}\n",
    "        GBRTModels = {}\n",
    "        for j in range(1, 11):\n",
    "            gbrtModels['Y_M_{}'.format(str(j))] = ensemble.GradientBoostingRegressor()\n",
    "        \n",
    "        #Use a dictionry to hold training label data\n",
    "        y_training = {}\n",
    "        for j in range(1, 11):\n",
    "            y_training['Y_M_{}'.format(str(j))] = dataPd['Y_M_{}'.format(str(j))]\n",
    "        \n",
    "        #Hold feature data for training\n",
    "        x_training = pd.DataFrame()\n",
    "        for j in range(len(featureColumns)):\n",
    "            x_training[featureColumns[j]] = dataPd[featureColumns[j]]\n",
    "\n",
    "        #Use a dictionry to hold testing label data\n",
    "        y_testing = {}\n",
    "        for j in range(1, 11):\n",
    "            y_testing['Y_M_{}'.format(str(j))] = data1d['Y_M_{}'.format(str(j))]\n",
    "\n",
    "        #Hold feature data for testing\n",
    "        x_testing = pd.DataFrame()\n",
    "        for j in range(len(featureColumns)):\n",
    "            x_testing[featureColumns[j]] = data1d[featureColumns[j]]\n",
    "\n",
    "        #Use a dictionry to hold predictions\n",
    "        y_prediction = {}\n",
    "\n",
    "        #timing the multi-Process prcessing\n",
    "        t = time.time()\n",
    "        \n",
    "        #Construction of models\n",
    "        ##Establish a number of Processs for the calculation tasks\n",
    "        pool = Pool(processes=numOfProcesses)\n",
    "\n",
    "        for j in range(1, 11):\n",
    "            GBRTModels['Y_M_{}'.format(str(j))] = pool.apply_async(gbrtModels['Y_M_{}'.format(str(j))].fit, args=(x_training, y_training['Y_M_{}'.format(str(j))]))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        print(\">>>Done with \" + str(numOfProcesses) + \" processes, and time taken is \" + str(time.time() - t)) \n",
    "\n",
    "        #Use the models to predict\n",
    "        for j in range(1, 11):\n",
    "            y_prediction['Y_M_{}'.format(str(j))] = GBRTModels['Y_M_{}'.format(str(j))].get().predict(x_testing)\n",
    "        \n",
    "        #Now, we store modeling results\n",
    "        for j in range(1, 11):\n",
    "            oneLineModelResult = []\n",
    "            oneLineModelResult.extend([str(date_index[i+p])])\n",
    "            oneLineModelResult.extend(['Y_M_{}'.format(str(j))])\n",
    "            oneLineModelResult.extend([GBRTModels['Y_M_{}'.format(str(j))].get().score(x_training, y_training['Y_M_{}'.format(str(j))])])\n",
    "            oneLineModelResult.extend([GBRTModels['Y_M_{}'.format(str(j))].get().score(x_testing, y_testing['Y_M_{}'.format(str(j))])])            \n",
    "            outputData = pd.concat([outputData, pd.DataFrame(data = [oneLineModelResult], columns = columns1)])\n",
    "\n",
    "    return outputData\n",
    "\n",
    "numOfPastDays = 10 \n",
    "numOfForwardDays = 1\n",
    "numOfProcesses = 8\n",
    "\n",
    "for future_ticker, df in df_all.items():\n",
    "    start_time = time.time()\n",
    "    outputData = modelConstructionAndForecasting(numOfPastDays, numOfForwardDays, df, numOfProcesses, featureCols, labelCols)      \n",
    "    end_time = time.time()\n",
    "    print('Time taken: ', end_time - start_time, 'seconds')\n",
    "    outputData.to_csv('./modelResultDataFile_{}.csv'.format(future_ticker), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
